{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6: Text Analysis and Natural Language Processing \n",
    "\n",
    "In this lab, we explore the text data provided by Kiva's API. Our primary source of textual data is the descriptive texts that borrowers submit for a loan request and are posted publicly on the Kiva website. Kiva is unique in that often, borrowers do not write descriptive requests for themselves, but fill out a questionnaire to Kiva's team of volunteer translators. We try to leverage this body of text (also called a *\"corpus\"*) to see if we can see any patterns in how an individual translator writes a description.\n",
    "\n",
    "As always, we first import our packages and read in our data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP-specific packages: \n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import names\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text  \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# output of multiple commands in a cell will be output at once.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# display up to 80 columns, this keeps everything visible\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datapath = '~/intro_to_machine_learning/data'\n",
    "datapath = '~/Desktop'\n",
    "df = pd.read_csv(datapath+'/df.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Feature Engineering\n",
    "\n",
    "We have very limited information about translators. In fact, the only variable in our dataset relevant to translators is their name! What information can we extract from this field? \n",
    "\n",
    "In text analysis, a common simple task is how to categorize names by gender. We know, just in our daily knoweldge of English names, that names that end in -a are likely to be female, and names that end in -o are likely to be male (for example, Jenna and Pablo). Since we have both the gender data and the name data for the borrowers, let's use borrowers' data to train a classifier model that can predict the gender from a name! Then, we will apply this model to the translators names to predict their genders. \n",
    "\n",
    "Here, we use the Naive Bayes Classifier (for a comprehensive review, take a look back at Module 6.) This algorithm assigns a label (in our case, \"male\" or \"female\") using the last letter of the name provided in the data. Remember that we first need to clean our data to ensure that we are capturing the last letter of first names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65751</th>\n",
       "      <td>Kavumbi</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100521</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>Benson</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25753</th>\n",
       "      <td>Mwatime</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>Mkambe</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106072</th>\n",
       "      <td>Kyalo</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44531</th>\n",
       "      <td>Amina</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20833</th>\n",
       "      <td>Amani</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94110</th>\n",
       "      <td>Grace</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63937</th>\n",
       "      <td>Samuel</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>Maurine</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Caroline</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36439</th>\n",
       "      <td>Happy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115232</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  gender\n",
       "65751    Kavumbi  Female\n",
       "100521     Nancy  Female\n",
       "19986      Daisy  Female\n",
       "19661     Benson    Male\n",
       "25753    Mwatime  Female\n",
       "22788     Mkambe  Female\n",
       "106072     Kyalo    Male\n",
       "44531      Amina  Female\n",
       "20833      Amani  Female\n",
       "94110      Grace  Female\n",
       "63937     Samuel    Male\n",
       "4345     Maurine  Female\n",
       "234     Caroline  Female\n",
       "36439      Happy  Female\n",
       "115232     Alice  Female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "105297"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create name and gender dataframe for single borrowers\n",
    "kiva_names = df[['name', 'gender', 'borrower_count']]\n",
    "kiva_names = kiva_names[['name', 'gender']][kiva_names['borrower_count'] == 1]\n",
    "\n",
    "kiva_names.sample(15)\n",
    "len(kiva_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there are some instances in which the name is not an individual's first name, but rather the name of a business or a collective, or \"Anonymous\". Let's drop these out of our training dataset as they won't be helpful in determining the gender of a person. \n",
    "\n",
    "Let's also select only the first name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9794"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0     Evaline\n",
       "1      Julias\n",
       "2        Rose\n",
       "3        Jane\n",
       "4       Alice\n",
       "5       Clare\n",
       "6        Mary\n",
       "7       James\n",
       "8     Jacinta\n",
       "9       Emily\n",
       "10     Fridah\n",
       "11    Charity\n",
       "12      Susan\n",
       "13      Joyce\n",
       "14     Daniel\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm null values, anonymous, and duplicates\n",
    "\n",
    "kiva_names = kiva_names.loc[kiva_names['name'].isnull() == False]\n",
    "kiva_names = kiva_names.drop_duplicates()\n",
    "kiva_names = kiva_names[kiva_names['name'] != \"Anonymous\"]\n",
    "kiva_names['name'] = kiva_names['name'].str.split(expand=True)[0]\n",
    "\n",
    "len(kiva_names['name'])\n",
    "kiva_names['name'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that will return the last letter of our borrowers' first names. This letter will be a **feature** we will use to attempt to predict the output feature, gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that returns last letter of first name \n",
    "def gender_features(name):\n",
    "    return {'last_letter': name[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare to train our model. We split train and test sets as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1958"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set training-test split %\n",
    "split_pct = 0.80\n",
    "\n",
    "# Remove null and NaN values \n",
    "kiva_names = kiva_names[pd.notnull(kiva_names)]\n",
    "\n",
    "# the pandas command \"sample\" already randomizes its selection. \n",
    "kiva_names_shuffled = kiva_names.sample(frac=1)\n",
    "\n",
    "kiva_train_set = kiva_names_shuffled[:int((len(kiva_names_shuffled)*split_pct))] \n",
    "kiva_test_set = kiva_names_shuffled[int(len(kiva_names_shuffled)*split_pct+1):]  \n",
    "\n",
    "len(kiva_train_set.index)\n",
    "len(kiva_test_set.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare our data by converting the name and gender features from features into lists, so they are associated with each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kiva_female_train = kiva_train_set[kiva_train_set['gender'] == \"Female\"]\n",
    "kiva_male_train = kiva_train_set[kiva_train_set['gender'] == \"Male\"]\n",
    "kiva_female_test = kiva_test_set[kiva_test_set['gender'] == \"Female\"]\n",
    "kiva_male_test = kiva_test_set[kiva_test_set['gender'] == \"Male\"]\n",
    "\n",
    "kiva_train_feature_set = [(name, \"female\") for name in kiva_female_train['name']] + \\\n",
    "[(name, \"male\") for name in kiva_male_train['name']]\n",
    "\n",
    "kiva_test_feature_set = [(name, \"female\") for name in kiva_female_test['name']] + \\\n",
    "[(name, \"male\") for name in kiva_male_test['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kiva_train_feature_set = [(gender_features(n), g) for (n, g) in kiva_train_feature_set]\n",
    "kiva_test_feature_set = [(gender_features(n), g) for (n, g) in kiva_test_feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kiva_classifier = nltk.NaiveBayesClassifier.train(kiva_train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's test out our new classifier! \n",
    "\n",
    "kiva_classifier.classify(gender_features('Cleopatra'))\n",
    "kiva_classifier.classify(gender_features('Maximillian'))\n",
    "kiva_classifier.classify(gender_features('James'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it works okay for our three samples, but let's get a better sense of overall accuracy.\n",
    "\n",
    "The nltk \"accuracy()\" method returns the % of time our predictions are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'w'              male : female =      9.4 : 1.0\n",
      "             last_letter = 'k'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'f'              male : female =      8.3 : 1.0\n",
      "             last_letter = 'p'              male : female =      3.9 : 1.0\n",
      "             last_letter = 's'              male : female =      3.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Find out which features were most informative in determining outcome\n",
    "\n",
    "kiva_classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show most informative features: this returns LIKELIHOOD RATIOS. For the first entry \"f\", we see that males are more likely to have this letter as their last letter by a factor of 9.3x.\n",
    "\n",
    "But how accurate is this? Let's run this classifier on our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6705822267620021\n"
     ]
    }
   ],
   "source": [
    "#Get a sense of overall accuracy\n",
    "\n",
    "print(nltk.classify.accuracy(kiva_classifier, kiva_test_feature_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction is okay, but not amazing. Remember that a random generator of genders would likely get an accuracy of about 50%, so at least we are better than random. One potential hypothesis for why we are not better at classifying genders might be because this particular dataset mixes Kenyan and American first names. Whereas you might expect an American female name to end in -a and an American male name to end in -o (e.g. Jenna and Julio), these conventions do not necessarily hold for Kenyan names. \n",
    "\n",
    "Since we see that the translators have primarily American names, let's try training a model using a corpus of American names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "0.602\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.5 : 1.0\n",
      "             last_letter = 'k'              male : female =     34.1 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     13.5 : 1.0\n",
      "             last_letter = 'v'              male : female =     12.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nltk_labeled_names = ([(name, \"male\") for name in names.words(\"male.txt\")] +\n",
    "                [(name, \"female\") for name in names.words(\"female.txt\")])\n",
    "\n",
    "nltk_feature_sets = [(gender_features(n), gender)\n",
    "                for (n, gender) in nltk_labeled_names]\n",
    "\n",
    "    # Divide the feature sets into training and test sets\n",
    "nltk_train_set, nltk_test_set = nltk_feature_sets[500:], nltk_feature_sets[:500]\n",
    "\n",
    "    # Train the naiveBayes classifier\n",
    "nltk_classifier = nltk.NaiveBayesClassifier.train(nltk_train_set)\n",
    "\n",
    "    # Test out the classifier with few samples outside of training set\n",
    "print(nltk_classifier.classify(gender_features(\"neo\")))  # returns male\n",
    "print(nltk_classifier.classify(gender_features(\"trinity\")))  # returns female\n",
    "\n",
    "    # Test the accuracy of the classifier on the test data\n",
    "print(nltk.classify.accuracy(nltk_classifier, nltk_test_set)) \n",
    "\n",
    "    # examine classifier to determine which feature is most effective for\n",
    "    # distinguishing the name's gender\n",
    "print(nltk_classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, our model using the Kiva data gets a slightly higher accuracy score. Let's use this model instead to try to predict translators' genders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translator_first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mohammad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cheryl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   translator_first_name\n",
       "0                  Julie\n",
       "1                 Morena\n",
       "8                   Lynn\n",
       "19              Mohammad\n",
       "21                Cheryl"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators = pd.DataFrame()\n",
    "translators['translator_first_name'] = df['translator.byline'].str.split(expand=True)[0]\n",
    "\n",
    "# rm null values and duplicates\n",
    "translators = translators.loc[translators['translator_first_name'].isnull() == False]\n",
    "translators = translators.drop_duplicates()\n",
    "\n",
    "translators.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'last_letter': 'e'}\n",
       "1     {'last_letter': 'a'}\n",
       "8     {'last_letter': 'n'}\n",
       "19    {'last_letter': 'd'}\n",
       "21    {'last_letter': 'l'}\n",
       "Name: last_letter, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators['last_letter'] = translators['translator_first_name'].apply(lambda x: gender_features(x))\n",
    "translators_last = translators['last_letter']\n",
    "translators_last[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translator_first_name</th>\n",
       "      <th>last_letter</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julie</td>\n",
       "      <td>{'last_letter': 'e'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morena</td>\n",
       "      <td>{'last_letter': 'a'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lynn</td>\n",
       "      <td>{'last_letter': 'n'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mohammad</td>\n",
       "      <td>{'last_letter': 'd'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cheryl</td>\n",
       "      <td>{'last_letter': 'l'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rita</td>\n",
       "      <td>{'last_letter': 'a'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Maureen</td>\n",
       "      <td>{'last_letter': 'n'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lorne</td>\n",
       "      <td>{'last_letter': 'e'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Caty</td>\n",
       "      <td>{'last_letter': 'y'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Trishna</td>\n",
       "      <td>{'last_letter': 'a'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   translator_first_name           last_letter  gender\n",
       "0                  Julie  {'last_letter': 'e'}  female\n",
       "1                 Morena  {'last_letter': 'a'}  female\n",
       "8                   Lynn  {'last_letter': 'n'}    male\n",
       "19              Mohammad  {'last_letter': 'd'}    male\n",
       "21                Cheryl  {'last_letter': 'l'}    male\n",
       "23                  Rita  {'last_letter': 'a'}  female\n",
       "25               Maureen  {'last_letter': 'n'}    male\n",
       "29                 Lorne  {'last_letter': 'e'}  female\n",
       "31                  Caty  {'last_letter': 'y'}  female\n",
       "34               Trishna  {'last_letter': 'a'}  female"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators['gender'] = translators_last.apply(lambda x: kiva_classifier.classify(x))\n",
    "translators.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - even in this small sample of 10, we see that the accuracy rate is far from perfect. Using our own understanding of what gender we would assign the names we see, this sample has an accuracy score of 60%. Not great.  \n",
    "\n",
    "**How can we make this prediction better? Can you think of other aspects of a name might be predictive of gender?** \n",
    "A quick test we can try is using the final two letters of a name instead of just one. Try it! \n",
    "\n",
    "We just completed our first supervised learning exercise: classification. Let's move forward in our question to finding patterns in the descriptions of the loans by translators, our unsupervised learning exercise. First we need to clean the text data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text \n",
    "\n",
    "Cleaning text is almost always required in text analysis. You have already gotten a taste of this in this notebook when you cleaned the variable \"name\" to exclude business names, and in past notebooks as well. \n",
    "\n",
    "Cleaning can be as extensive as you want it to be, depending on what serves your research question the best. Is it best to look at full sentences, so you can retain the context of words? Is it best to look at individual words? Should you remove grammar, HTML code, stopwords? \n",
    "\n",
    "Before answering this question, we have to know what's in our data. Let's turn to some exploratory analyses to determine how we should clean our data.\n",
    "\n",
    "Note that we don't run the following snippets of code on the whole dataset as text analysis is very computationally expensive and may crash your computer. Instead, we draw a sample of 100 descriptions from the dataset. *This means that your results will look slightly different, but that's okay -- make sure to post on Slack anything you find interesting!*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mercy is a widow and blessed with three children who are still in school.  She runs a hardware shop to support her  family. She has been in this business for three years.  She also runs a green grocer to earn extra income.  She has employed one person to help her manage the business.  \\r\\r\\n\\r\\r\\nMercy is requesting for a loan of 20,000 Kenyan shillings to buy paints and bolts for resale. In the next 5 years, she wants to expand her business.', 'Jackson is the father of seven between the ages of 23 and 6 and lives with his family in his hometown area of Nyamira, North Rift, Kenya. He has two farmhands and his farm produces tea, coffee, bananas and maize. He makes additional income from his trade in animals within the local market.\\r\\r\\n\\r\\r\\nJackson has requested a loan of 35,000 KES from Juhudi Kilimo to purchase and insure a dairy cow. He says he will use the income to pay for the education of his children and raise their living standards. He plans to own five cows and construct a modern dairy unit for his animals.\\r\\r\\n\\r\\r\\nJackson is grateful for the loans provided by Juhudi Kilimo but says animal diseases and rampant theft of cows are great threats to dairy farming. ', \"Joseph is an ambitious 41-year-old man who has been operating a barber shop for six years.  He also practices mixed farming for commercial use and for his own consumption.  His wife is also a business-lady who runs a green grocer shop.  Joseph uses his money to educate his four children, provide for his family's basic needs and to pay wages to his two employees.  \\r\\r\\n\\r\\r\\nHe appreciates that since he joined Faulu Kenya, his sales have increased hence his living standards have improved.  He saves part of his income with Faulu Kenya and he plans to take a loan of 20,000 Kenyan shillings to open up a salon.  Therefore, he wants to buy a hair blow drier, hair products and hair drier.  He hopes to establish a permanent home for his family in the future.    \"]\n"
     ]
    }
   ],
   "source": [
    "# read all non-null text into a single df\n",
    "text_raw = df['description.texts.en'][df['description.texts.en'].isnull() == False]\n",
    "\n",
    "# take sample of 100 entries, read into list\n",
    "sample_num = 100\n",
    "text_raw_abridged = text_raw.sample(sample_num)\n",
    "text = list(map(str, text_raw_abridged))\n",
    "\n",
    "print(text[0:3]) # Each sentence is an item in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is some HTML/CSS cluttering up the text. Below, we remove these and convert all capital letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mercy is a widow and blessed with three children who are still in school  she runs a hardware shop to support her  family she has been in this business for three years  she also runs a green grocer to earn extra income  she has employed one person to help her manage the business  mercy is requesting for a loan of 20000 kenyan shillings to buy paints and bolts for resale in the next 5 years she wants to expand her business', 'jackson is the father of seven between the ages of 23 and 6 and lives with his family in his hometown area of nyamira north rift kenya he has two farmhands and his farm produces tea coffee bananas and maize he makes additional income from his trade in animals within the local marketjackson has requested a loan of 35000 kes from juhudi kilimo to purchase and insure a dairy cow he says he will use the income to pay for the education of his children and raise their living standards he plans to own five cows and construct a modern dairy unit for his animalsjackson is grateful for the loans provided by juhudi kilimo but says animal diseases and rampant theft of cows are great threats to dairy farming ', \"joseph is an ambitious 41-year-old man who has been operating a barber shop for six years  he also practices mixed farming for commercial use and for his own consumption  his wife is also a business-lady who runs a green grocer shop  joseph uses his money to educate his four children provide for his family's basic needs and to pay wages to his two employees  he appreciates that since he joined faulu kenya his sales have increased hence his living standards have improved  he saves part of his income with faulu kenya and he plans to take a loan of 20000 kenyan shillings to open up a salon  therefore he wants to buy a hair blow drier hair products and hair drier  he hopes to establish a permanent home for his family in the future    \"]\n"
     ]
    }
   ],
   "source": [
    "# Remove HTML \n",
    "text = [w.replace('\\r', '') for w in text]\n",
    "text = [w.replace('\\n', '') for w in text]\n",
    "text = [w.replace('<br />', '') for w in text]\n",
    "text = [w.replace('.', '') for w in text]\n",
    "text = [w.replace(',', '') for w in text]\n",
    "\n",
    "# Lowercase\n",
    "text = [w.lower() for w in text]\n",
    "\n",
    "print(text[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The text looks clean. We also notice that this dataset is a list where every item in the list is a description. Now we tokenize each item in the list so that each word is separated out. This yields a list of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mercy',\n",
       "  'is',\n",
       "  'a',\n",
       "  'widow',\n",
       "  'and',\n",
       "  'blessed',\n",
       "  'with',\n",
       "  'three',\n",
       "  'children',\n",
       "  'who',\n",
       "  'are',\n",
       "  'still',\n",
       "  'in',\n",
       "  'school',\n",
       "  'she',\n",
       "  'runs',\n",
       "  'a',\n",
       "  'hardware',\n",
       "  'shop',\n",
       "  'to',\n",
       "  'support',\n",
       "  'her',\n",
       "  'family',\n",
       "  'she',\n",
       "  'has',\n",
       "  'been',\n",
       "  'in',\n",
       "  'this',\n",
       "  'business',\n",
       "  'for',\n",
       "  'three',\n",
       "  'years',\n",
       "  'she',\n",
       "  'also',\n",
       "  'runs',\n",
       "  'a',\n",
       "  'green',\n",
       "  'grocer',\n",
       "  'to',\n",
       "  'earn',\n",
       "  'extra',\n",
       "  'income',\n",
       "  'she',\n",
       "  'has',\n",
       "  'employed',\n",
       "  'one',\n",
       "  'person',\n",
       "  'to',\n",
       "  'help',\n",
       "  'her',\n",
       "  'manage',\n",
       "  'the',\n",
       "  'business',\n",
       "  'mercy',\n",
       "  'is',\n",
       "  'requesting',\n",
       "  'for',\n",
       "  'a',\n",
       "  'loan',\n",
       "  'of',\n",
       "  '20000',\n",
       "  'kenyan',\n",
       "  'shillings',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'paints',\n",
       "  'and',\n",
       "  'bolts',\n",
       "  'for',\n",
       "  'resale',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  '5',\n",
       "  'years',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'expand',\n",
       "  'her',\n",
       "  'business'],\n",
       " ['jackson',\n",
       "  'is',\n",
       "  'the',\n",
       "  'father',\n",
       "  'of',\n",
       "  'seven',\n",
       "  'between',\n",
       "  'the',\n",
       "  'ages',\n",
       "  'of',\n",
       "  '23',\n",
       "  'and',\n",
       "  '6',\n",
       "  'and',\n",
       "  'lives',\n",
       "  'with',\n",
       "  'his',\n",
       "  'family',\n",
       "  'in',\n",
       "  'his',\n",
       "  'hometown',\n",
       "  'area',\n",
       "  'of',\n",
       "  'nyamira',\n",
       "  'north',\n",
       "  'rift',\n",
       "  'kenya',\n",
       "  'he',\n",
       "  'has',\n",
       "  'two',\n",
       "  'farmhands',\n",
       "  'and',\n",
       "  'his',\n",
       "  'farm',\n",
       "  'produces',\n",
       "  'tea',\n",
       "  'coffee',\n",
       "  'bananas',\n",
       "  'and',\n",
       "  'maize',\n",
       "  'he',\n",
       "  'makes',\n",
       "  'additional',\n",
       "  'income',\n",
       "  'from',\n",
       "  'his',\n",
       "  'trade',\n",
       "  'in',\n",
       "  'animals',\n",
       "  'within',\n",
       "  'the',\n",
       "  'local',\n",
       "  'marketjackson',\n",
       "  'has',\n",
       "  'requested',\n",
       "  'a',\n",
       "  'loan',\n",
       "  'of',\n",
       "  '35000',\n",
       "  'kes',\n",
       "  'from',\n",
       "  'juhudi',\n",
       "  'kilimo',\n",
       "  'to',\n",
       "  'purchase',\n",
       "  'and',\n",
       "  'insure',\n",
       "  'a',\n",
       "  'dairy',\n",
       "  'cow',\n",
       "  'he',\n",
       "  'says',\n",
       "  'he',\n",
       "  'will',\n",
       "  'use',\n",
       "  'the',\n",
       "  'income',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'the',\n",
       "  'education',\n",
       "  'of',\n",
       "  'his',\n",
       "  'children',\n",
       "  'and',\n",
       "  'raise',\n",
       "  'their',\n",
       "  'living',\n",
       "  'standards',\n",
       "  'he',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'own',\n",
       "  'five',\n",
       "  'cows',\n",
       "  'and',\n",
       "  'construct',\n",
       "  'a',\n",
       "  'modern',\n",
       "  'dairy',\n",
       "  'unit',\n",
       "  'for',\n",
       "  'his',\n",
       "  'animalsjackson',\n",
       "  'is',\n",
       "  'grateful',\n",
       "  'for',\n",
       "  'the',\n",
       "  'loans',\n",
       "  'provided',\n",
       "  'by',\n",
       "  'juhudi',\n",
       "  'kilimo',\n",
       "  'but',\n",
       "  'says',\n",
       "  'animal',\n",
       "  'diseases',\n",
       "  'and',\n",
       "  'rampant',\n",
       "  'theft',\n",
       "  'of',\n",
       "  'cows',\n",
       "  'are',\n",
       "  'great',\n",
       "  'threats',\n",
       "  'to',\n",
       "  'dairy',\n",
       "  'farming']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(map(word_tokenize, text))\n",
    "kiva_text = nltk.Text(tokens)\n",
    "kiva_text[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary investigations / visualizations \n",
    "\n",
    "Now that we've got cleaned data, let's conduct some preliminary investigations. Frequency, concordance and similar are all functions of the NLTK package that can give us a sense of what is in our text without our having to read every single line.\n",
    "\n",
    "- Frequency\n",
    "- Concordance\n",
    "- Similar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency returns a list of unique words, with how often each word shows up in the corpus. This provides an idea of what words are included in the descriptions of loan requests in Kenya. Note that the most common words are relatively uninformative, such as \"to,\" \"and,\" or \"is.\" Later we will remove these for analysis so they do not overinfluence our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read all sentences into single list \n",
    "\n",
    "text_corpus = list() \n",
    "\n",
    "for x in range(0, len(kiva_text)): \n",
    "    text_corpus.extend(kiva_text[x])\n",
    "\n",
    "text_corpus = nltk.Text(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 492),\n",
       " ('and', 432),\n",
       " ('a', 388),\n",
       " ('the', 375),\n",
       " ('she', 337),\n",
       " ('is', 303),\n",
       " ('her', 297),\n",
       " ('of', 294),\n",
       " ('in', 228),\n",
       " ('for', 194),\n",
       " ('has', 186),\n",
       " ('business', 183),\n",
       " ('loan', 152),\n",
       " ('he', 151),\n",
       " ('his', 146),\n",
       " ('will', 136),\n",
       " ('years', 134),\n",
       " ('with', 117),\n",
       " ('this', 110),\n",
       " ('children', 102),\n",
       " ('that', 87),\n",
       " ('been', 85),\n",
       " ('from', 80),\n",
       " ('be', 70),\n",
       " ('married', 67)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kiva_fdist.plot()\n",
    "#kiva_fdist.plot(50, cumulative=True)\n",
    "kiva_fdist = nltk.FreqDist(text_corpus)\n",
    "kiva_fdist.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concordance takes an input word of your choosing and returns the surrounding words. This provides important context about how a specific word is used in the text corpus. Here, we test \"future\", \"seasonality\", and \"working\". Note that sme of these words are used differently or ambiguously. This gets at an important point for NLP - words can be and are used ambiguously and it is difficult to parse meaning unless we also take a look at context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 29 matches:\n",
      "ermanent home for his family in the future tabu is a married woman with three \n",
      "ithin 5 years she hopes that in the future , she will have improved living sta\n",
      "ls for resale she hopes that in the future she will be successful this is her \n",
      " dvd players , tv sets , etc in the future , he wants to educate his children \n",
      "ishing another business in the near future isaac does farming in thika town an\n",
      " term from visionfund kenya and his future hopes are to expand his farming bus\n",
      "hool will help them have a brighter future lend $ 25 towards this loan and emp\n",
      "ithin 5 years she hopes that in the future , she will live a comfortable life \n",
      "ess to open up a general shopin the future , he hopes to have a wholesale busi\n",
      "usinessher hopes and dreams for the future are to have a good inventory and in\n",
      "o be a clothes and shoe supplier in future with a five-year plan of opening mo\n",
      "ithin 5 years she hopes that in the future , she will be a successful business\n",
      " profits to improve her farming her future hopes and dreams are to be financia\n",
      "d establishing a retail shop in the future james is a farmer living in the nda\n",
      "lizabeth hopes to buy a taxi in the future which will increase her income musu\n",
      "hine , bread , etc his goal for the future is to have a bigger store billiah i\n",
      "earned her hopes and dreams for the future are to expand her shop and buy a pl\n",
      "iving conditions , and securing the future of his school-going childrenhelp th\n",
      "the loan and start a retail shophis future dreams are to be financially stable\n",
      "ithin 5 years she hopes that in the future , she will have good living conditi\n",
      "uding sugar , salt and flour in the future , she hopes to expand her business \n",
      " establish a restaurant in the near future zainabu is a married mother of five\n",
      "n intends to save more money in the future so that she can develop her farming\n",
      "ill be able to secure her family 's future rael is 32 years old , married to d\n",
      "ts she gets will act as savings for future developments and will also be used \n"
     ]
    }
   ],
   "source": [
    "text_corpus.concordance('future')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "e cites her major challenge to be seasonality mariam dreams of establishing a b\n",
      "by she faces a major challenge of seasonality in her business she dreams to exp\n",
      "ineâ€™s major business challenge is seasonality she owns a house without electric\n",
      "public her primary challenges are seasonality and lack of enough capital to ens\n",
      "the challenges of competition and seasonality in her business with the kshs 30,\n"
     ]
    }
   ],
   "source": [
    "text_corpus.concordance('seasonality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 12 of 12 matches:\n",
      "to start dairy farming he is a hard working man who is determined to achieve hi\n",
      "hardworking individual she has been working alongside one acre fund since 2013 \n",
      " hardworking individual he has been working alongside one acre fund since 2014 \n",
      "business challenge to be inadequate working capital she will use the kes 60,000\n",
      "business challenge to be inadequate working capital she will use the 30,000 kes\n",
      "ve five children : hillary , 26 and working ; lucy , 18 and in form two ; lilli\n",
      "business challenge to be inadequate working capital she will use the kes 50,000\n",
      "hant two years ago with the goal of working on her own to support her household\n",
      "very resourceful person he has been working alongside one acre fund since 2015 \n",
      "the people make their livelihood by working as laborers in the agricultural fie\n",
      "business challenge to be inadequate working capital she will use the kes 60,000\n",
      "strict < p > in 2010 hellen started working with the one acre fund she decided \n"
     ]
    }
   ],
   "source": [
    "text_corpus.concordance('working')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar takes in an input word of your choosing, but returns other words that appear in a similar range of contexts. This is called finding the \"distributional similarity.\" Most similar words appear first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan kshs school business father ages area kes purchase use education\n",
      "loans part home challenge goal photo group training leader\n"
     ]
    }
   ],
   "source": [
    "text_corpus.similar(\"future\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business years farm neighbors family income home village community in\n",
      "the loan own cows farming wife money educate married selling\n"
     ]
    }
   ],
   "source": [
    "text_corpus.similar(\"children\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "\n",
    "\"Stop words\" are words like \"to\", \"the\", \"a\" - words that are plentiful but do not offer any meaningful information about the document. Here, we import a predetermined set of stop words defined by the NLTK package and then remove them from the dataset. The resulting dataset has words that we can generally agree are meaningful and say something about the content of the loan request. You can also define your own set of \"stop words\" to remove if you have a very specific set of words you want to remove. \n",
    "\n",
    "However, we see that these words still have suffixes such as \"-s\" and \"-ing\". We want to remove these because if we do not, the algorithm will count a set of words like \"married\" and \"marries\" as different words, when we can consider them, for our purposes, the same word. To remove these, we stem our text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mercy',\n",
       " 'widow',\n",
       " 'blessed',\n",
       " 'three',\n",
       " 'children',\n",
       " 'still',\n",
       " 'school',\n",
       " 'runs',\n",
       " 'hardware',\n",
       " 'shop',\n",
       " 'support',\n",
       " 'family',\n",
       " 'business',\n",
       " 'three',\n",
       " 'years',\n",
       " 'also',\n",
       " 'runs',\n",
       " 'green',\n",
       " 'grocer',\n",
       " 'earn',\n",
       " 'extra',\n",
       " 'income',\n",
       " 'employed',\n",
       " 'one',\n",
       " 'person',\n",
       " 'help',\n",
       " 'manage',\n",
       " 'business',\n",
       " 'mercy',\n",
       " 'requesting',\n",
       " 'loan',\n",
       " '20000',\n",
       " 'kenyan',\n",
       " 'shillings',\n",
       " 'buy',\n",
       " 'paints',\n",
       " 'bolts',\n",
       " 'resale',\n",
       " 'next',\n",
       " '5',\n",
       " 'years',\n",
       " 'wants',\n",
       " 'expand',\n",
       " 'business',\n",
       " 'jackson',\n",
       " 'father',\n",
       " 'seven',\n",
       " 'ages',\n",
       " '23',\n",
       " '6']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words\n",
    "\n",
    "text_corpus_clean = [word for word in text_corpus if word not in stopwords.words('english')]\n",
    "text_corpus_clean[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem words \n",
    "\n",
    "The Porter Stemmer is one of several stemming tools (including Snowball Stemmer and the Lancaster Stemmer). Each type of stemmer uses different rules to \"stem\" a word like \"running\" to \"run\". Here we use the Porter Stemmer as it is very commonly used. Try others! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merci',\n",
       " 'widow',\n",
       " 'bless',\n",
       " 'three',\n",
       " 'children',\n",
       " 'still',\n",
       " 'school',\n",
       " 'run',\n",
       " 'hardwar',\n",
       " 'shop',\n",
       " 'support',\n",
       " 'famili',\n",
       " 'busi',\n",
       " 'three',\n",
       " 'year',\n",
       " 'also',\n",
       " 'run',\n",
       " 'green',\n",
       " 'grocer',\n",
       " 'earn',\n",
       " 'extra',\n",
       " 'incom',\n",
       " 'employ',\n",
       " 'one',\n",
       " 'person',\n",
       " 'help',\n",
       " 'manag',\n",
       " 'busi',\n",
       " 'merci',\n",
       " 'request',\n",
       " 'loan',\n",
       " '20000',\n",
       " 'kenyan',\n",
       " 'shill',\n",
       " 'buy',\n",
       " 'paint',\n",
       " 'bolt',\n",
       " 'resal',\n",
       " 'next',\n",
       " '5',\n",
       " 'year',\n",
       " 'want',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'jackson',\n",
       " 'father',\n",
       " 'seven',\n",
       " 'age',\n",
       " '23',\n",
       " '6',\n",
       " 'live',\n",
       " 'famili',\n",
       " 'hometown',\n",
       " 'area',\n",
       " 'nyamira',\n",
       " 'north',\n",
       " 'rift',\n",
       " 'kenya',\n",
       " 'two',\n",
       " 'farmhand',\n",
       " 'farm',\n",
       " 'produc',\n",
       " 'tea',\n",
       " 'coffe',\n",
       " 'banana',\n",
       " 'maiz',\n",
       " 'make',\n",
       " 'addit',\n",
       " 'incom',\n",
       " 'trade',\n",
       " 'anim',\n",
       " 'within',\n",
       " 'local',\n",
       " 'marketjackson',\n",
       " 'request',\n",
       " 'loan',\n",
       " '35000',\n",
       " 'ke',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'purchas',\n",
       " 'insur',\n",
       " 'dairi',\n",
       " 'cow',\n",
       " 'say',\n",
       " 'use',\n",
       " 'incom',\n",
       " 'pay',\n",
       " 'educ',\n",
       " 'children',\n",
       " 'rais',\n",
       " 'live',\n",
       " 'standard',\n",
       " 'plan',\n",
       " 'five',\n",
       " 'cow',\n",
       " 'construct',\n",
       " 'modern',\n",
       " 'dairi',\n",
       " 'unit',\n",
       " 'animalsjackson',\n",
       " 'grate',\n",
       " 'loan',\n",
       " 'provid',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'say',\n",
       " 'anim',\n",
       " 'diseas',\n",
       " 'rampant',\n",
       " 'theft',\n",
       " 'cow',\n",
       " 'great',\n",
       " 'threat',\n",
       " 'dairi',\n",
       " 'farm',\n",
       " 'joseph',\n",
       " 'ambiti',\n",
       " '41-year-old',\n",
       " 'man',\n",
       " 'oper',\n",
       " 'barber',\n",
       " 'shop',\n",
       " 'six',\n",
       " 'year',\n",
       " 'also',\n",
       " 'practic',\n",
       " 'mix',\n",
       " 'farm',\n",
       " 'commerci',\n",
       " 'use',\n",
       " 'consumpt',\n",
       " 'wife',\n",
       " 'also',\n",
       " 'business-ladi',\n",
       " 'run',\n",
       " 'green',\n",
       " 'grocer',\n",
       " 'shop',\n",
       " 'joseph',\n",
       " 'use',\n",
       " 'money',\n",
       " 'educ',\n",
       " 'four',\n",
       " 'children',\n",
       " 'provid',\n",
       " 'famili',\n",
       " \"'s\",\n",
       " 'basic',\n",
       " 'need',\n",
       " 'pay',\n",
       " 'wage',\n",
       " 'two',\n",
       " 'employe',\n",
       " 'appreci',\n",
       " 'sinc',\n",
       " 'join',\n",
       " 'faulu',\n",
       " 'kenya',\n",
       " 'sale',\n",
       " 'increas',\n",
       " 'henc',\n",
       " 'live',\n",
       " 'standard',\n",
       " 'improv',\n",
       " 'save',\n",
       " 'part',\n",
       " 'incom',\n",
       " 'faulu',\n",
       " 'kenya',\n",
       " 'plan',\n",
       " 'take',\n",
       " 'loan',\n",
       " '20000',\n",
       " 'kenyan',\n",
       " 'shill',\n",
       " 'open',\n",
       " 'salon',\n",
       " 'therefor',\n",
       " 'want',\n",
       " 'buy',\n",
       " 'hair',\n",
       " 'blow',\n",
       " 'drier',\n",
       " 'hair',\n",
       " 'product',\n",
       " 'hair',\n",
       " 'drier',\n",
       " 'hope',\n",
       " 'establish',\n",
       " 'perman',\n",
       " 'home',\n",
       " 'famili',\n",
       " 'futur',\n",
       " 'tabu',\n",
       " 'marri',\n",
       " 'woman',\n",
       " 'three',\n",
       " 'children',\n",
       " 'attend',\n",
       " 'school',\n",
       " 'live',\n",
       " 'rental',\n",
       " 'hous',\n",
       " 'electr',\n",
       " 'pipe',\n",
       " 'waterh',\n",
       " 'greatest',\n",
       " 'monthli',\n",
       " 'expens',\n",
       " 'rentsh',\n",
       " 'oper',\n",
       " 'retail',\n",
       " 'shop',\n",
       " 'busi',\n",
       " 'past',\n",
       " 'four',\n",
       " 'year',\n",
       " 'sell',\n",
       " 'household',\n",
       " 'consum',\n",
       " 'like',\n",
       " 'wheat',\n",
       " 'flour',\n",
       " 'maiz',\n",
       " 'flour',\n",
       " 'sugar',\n",
       " 'face',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'theft',\n",
       " 'businesswith',\n",
       " 'loan',\n",
       " 'request',\n",
       " 'want',\n",
       " 'purchas',\n",
       " 'stock',\n",
       " 'sugar',\n",
       " 'rice',\n",
       " 'maiz',\n",
       " 'flour',\n",
       " 'wheat',\n",
       " 'flour',\n",
       " 'decid',\n",
       " 'join',\n",
       " 'yehu',\n",
       " 'access',\n",
       " 'loan',\n",
       " 'boost',\n",
       " 'busi',\n",
       " 'alfr',\n",
       " 'resid',\n",
       " 'nyamira',\n",
       " 'south',\n",
       " 'rift',\n",
       " 'kenya',\n",
       " 'father',\n",
       " 'four',\n",
       " 'children',\n",
       " 'age',\n",
       " '17',\n",
       " '4',\n",
       " 'year',\n",
       " 'school',\n",
       " 'farm',\n",
       " '15',\n",
       " 'year',\n",
       " 'sell',\n",
       " 'product',\n",
       " 'includ',\n",
       " 'tea',\n",
       " 'milk',\n",
       " 'maiz',\n",
       " 'local',\n",
       " 'market',\n",
       " 'also',\n",
       " 'work',\n",
       " 'carpent',\n",
       " 'besid',\n",
       " 'farmingalfr',\n",
       " 'made',\n",
       " 'loan',\n",
       " 'request',\n",
       " 'amount',\n",
       " '45000',\n",
       " 'ke',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'buy',\n",
       " 'dairi',\n",
       " 'cow',\n",
       " 'say',\n",
       " 'dairi',\n",
       " 'cow',\n",
       " 'improv',\n",
       " 'famili',\n",
       " 'upkeep',\n",
       " 'earn',\n",
       " 'incom',\n",
       " 'educ',\n",
       " 'children',\n",
       " 'plan',\n",
       " 'expand',\n",
       " 'carpentri',\n",
       " 'workshop',\n",
       " 'dairi',\n",
       " 'busi',\n",
       " 'add',\n",
       " 'current',\n",
       " 'product',\n",
       " 'yield',\n",
       " 'especi',\n",
       " 'maiz',\n",
       " 'low',\n",
       " 'meet',\n",
       " 'famili',\n",
       " \"'s\",\n",
       " 'need',\n",
       " 'call',\n",
       " 'diversif',\n",
       " 'well',\n",
       " 'expans',\n",
       " 'product',\n",
       " 'dairi',\n",
       " 'businessalfr',\n",
       " 'lament',\n",
       " 'poor',\n",
       " 'road',\n",
       " 'network',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'especi',\n",
       " 'deliveri',\n",
       " 'product',\n",
       " 'market',\n",
       " 'gladi',\n",
       " 'marri',\n",
       " 'woman',\n",
       " '1',\n",
       " 'child',\n",
       " 'describ',\n",
       " 'honest',\n",
       " 'oper',\n",
       " 'retail',\n",
       " 'busi',\n",
       " 'sell',\n",
       " 'fish',\n",
       " 'involv',\n",
       " 'busi',\n",
       " '5',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'popul',\n",
       " 'area',\n",
       " 'primari',\n",
       " 'custom',\n",
       " 'local',\n",
       " 'describ',\n",
       " 'biggest',\n",
       " 'busi',\n",
       " 'challeng',\n",
       " 'insuffici',\n",
       " 'fund',\n",
       " 'use',\n",
       " 'ke',\n",
       " '20000',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'fish',\n",
       " 'fri',\n",
       " 'pan',\n",
       " 'busi',\n",
       " 'goal',\n",
       " 'supplier',\n",
       " 'within',\n",
       " '5',\n",
       " 'year',\n",
       " 'hope',\n",
       " 'futur',\n",
       " 'improv',\n",
       " 'live',\n",
       " 'standard',\n",
       " 'first',\n",
       " 'loan',\n",
       " 'smep',\n",
       " 'microfin',\n",
       " 'bank',\n",
       " 'john',\n",
       " 'marri',\n",
       " 'man',\n",
       " 'five',\n",
       " 'children',\n",
       " 'age',\n",
       " 'rang',\n",
       " '8',\n",
       " 'year',\n",
       " '19',\n",
       " 'year',\n",
       " 'describ',\n",
       " 'focus',\n",
       " 'oper',\n",
       " 'retail',\n",
       " 'busi',\n",
       " 'sell',\n",
       " 'maiz',\n",
       " 'involv',\n",
       " 'busi',\n",
       " 'three',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'rural',\n",
       " 'area',\n",
       " 'primari',\n",
       " 'custom',\n",
       " 'local',\n",
       " 'use',\n",
       " 'ke',\n",
       " '20000',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'stock',\n",
       " 'maiz',\n",
       " 'busi',\n",
       " 'goal',\n",
       " 'excel',\n",
       " 'within',\n",
       " 'five',\n",
       " 'year',\n",
       " 'third',\n",
       " 'loan',\n",
       " 'smep',\n",
       " 'microfin',\n",
       " 'bank',\n",
       " 'previou',\n",
       " 'loan',\n",
       " 'repaid',\n",
       " 'success',\n",
       " 'person',\n",
       " 'rais',\n",
       " 'hand',\n",
       " 'photo',\n",
       " 'selina',\n",
       " 'member',\n",
       " 'magar',\n",
       " 'hope',\n",
       " 'women',\n",
       " 'group',\n",
       " '55',\n",
       " 'year',\n",
       " 'old',\n",
       " 'marri',\n",
       " 'bless',\n",
       " 'eight',\n",
       " 'children',\n",
       " 'join',\n",
       " 'hand',\n",
       " 'hand',\n",
       " 'eastern',\n",
       " 'africa',\n",
       " '2015',\n",
       " 'benefit',\n",
       " 'train',\n",
       " 'enterpris',\n",
       " 'develop',\n",
       " 'financi',\n",
       " 'manag',\n",
       " 'crop',\n",
       " 'farm',\n",
       " 'maiz',\n",
       " 'bean',\n",
       " 'borrow',\n",
       " 'kiva',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'qualiti',\n",
       " 'fertil',\n",
       " 'certifi',\n",
       " 'seed',\n",
       " 'boost',\n",
       " 'crop',\n",
       " 'yield',\n",
       " 'henc',\n",
       " 'increas',\n",
       " 'incom',\n",
       " 'pay',\n",
       " 'school',\n",
       " 'fee',\n",
       " 'three',\n",
       " 'children',\n",
       " 'grate',\n",
       " 'kiva',\n",
       " 'lender',\n",
       " 'support',\n",
       " 'promis',\n",
       " 'repay',\n",
       " 'loan',\n",
       " 'promptli',\n",
       " 'pictur',\n",
       " 'consolata',\n",
       " 'often',\n",
       " 'describ',\n",
       " 'extrem',\n",
       " 'reliabl',\n",
       " 'person',\n",
       " '31',\n",
       " 'year',\n",
       " 'old',\n",
       " 'group',\n",
       " 'leader',\n",
       " 'repres',\n",
       " 'group',\n",
       " '15',\n",
       " 'farmer',\n",
       " 'teso',\n",
       " 'district',\n",
       " 'kenya',\n",
       " 'marri',\n",
       " 'two',\n",
       " 'childrenconsolata',\n",
       " 'return',\n",
       " 'season',\n",
       " 'work',\n",
       " 'one',\n",
       " 'acr',\n",
       " 'fund',\n",
       " 'mean',\n",
       " 'abl',\n",
       " 'access',\n",
       " 'best',\n",
       " 'seed',\n",
       " 'price',\n",
       " 'decid',\n",
       " 'join',\n",
       " 'first',\n",
       " 'place',\n",
       " 'consolata',\n",
       " 'say',\n",
       " 'happi',\n",
       " 'made',\n",
       " 'decis',\n",
       " 'sinc',\n",
       " 'first',\n",
       " 'join',\n",
       " '2015',\n",
       " 'abl',\n",
       " 'consist',\n",
       " 'feed',\n",
       " 'famili',\n",
       " 'improv',\n",
       " 'day-to-day',\n",
       " 'life',\n",
       " 'significantli',\n",
       " 'consolata',\n",
       " 'use',\n",
       " 'profit',\n",
       " 'season',\n",
       " 'buy',\n",
       " 'cowth',\n",
       " 'group',\n",
       " 'use',\n",
       " 'loan',\n",
       " 'purchas',\n",
       " 'seed',\n",
       " 'fertil',\n",
       " 'plant',\n",
       " 'total',\n",
       " '475',\n",
       " 'acr',\n",
       " 'given',\n",
       " 'member',\n",
       " 'group',\n",
       " 'also',\n",
       " 'purchas',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'loan',\n",
       " 'group',\n",
       " 'also',\n",
       " 'receiv',\n",
       " 'total',\n",
       " '13',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'beth',\n",
       " 'marri',\n",
       " 'woman',\n",
       " 'three',\n",
       " 'children',\n",
       " 'describ',\n",
       " 'ambiti',\n",
       " 'oper',\n",
       " 'farm',\n",
       " 'grow',\n",
       " 'maiz',\n",
       " 'crop',\n",
       " 'sell',\n",
       " 'involv',\n",
       " 'busi',\n",
       " '10',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'good',\n",
       " 'area',\n",
       " 'primari',\n",
       " 'custom',\n",
       " 'local',\n",
       " 'use',\n",
       " 'ke',\n",
       " '15000',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'stock',\n",
       " 'cereal',\n",
       " 'resal',\n",
       " 'hope',\n",
       " 'futur',\n",
       " 'success',\n",
       " 'first',\n",
       " 'loan',\n",
       " 'smep',\n",
       " 'microfin',\n",
       " 'bank',\n",
       " 'florenc',\n",
       " 'marri',\n",
       " 'six',\n",
       " 'children',\n",
       " 'nyamira',\n",
       " 'kenya',\n",
       " 'past',\n",
       " '45',\n",
       " 'year',\n",
       " 'florenc',\n",
       " 'involv',\n",
       " 'mix',\n",
       " 'farm',\n",
       " 'primari',\n",
       " 'sourc',\n",
       " 'incom',\n",
       " 'milk',\n",
       " 'egg',\n",
       " 'person',\n",
       " 'busi',\n",
       " 'engag',\n",
       " 'make',\n",
       " 'extra',\n",
       " 'cash',\n",
       " 'florenc',\n",
       " 'abl',\n",
       " 'provid',\n",
       " 'nutriti',\n",
       " 'food',\n",
       " 'famili',\n",
       " 'passion',\n",
       " 'love',\n",
       " 'poultri',\n",
       " 'farm',\n",
       " 'biggest',\n",
       " 'challeng',\n",
       " 'face',\n",
       " 'lack',\n",
       " 'capit',\n",
       " 'buy',\n",
       " 'addit',\n",
       " 'poultri',\n",
       " 'bird',\n",
       " 'florenc',\n",
       " 'request',\n",
       " 'loan',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'use',\n",
       " 'purchas',\n",
       " 'high-qual',\n",
       " 'poultri',\n",
       " 'breed',\n",
       " 'resist',\n",
       " 'diseas',\n",
       " 'lay',\n",
       " 'egg',\n",
       " 'believ',\n",
       " 'excess',\n",
       " 'maiz',\n",
       " 'use',\n",
       " 'feed',\n",
       " 'poultri',\n",
       " 'sorghum',\n",
       " 'use',\n",
       " 'give',\n",
       " 'poultri',\n",
       " 'energi',\n",
       " 'green',\n",
       " 'gram',\n",
       " 'use',\n",
       " 'protein',\n",
       " 'better',\n",
       " 'feed',\n",
       " 'poultri',\n",
       " 'increas',\n",
       " 'egg',\n",
       " 'product',\n",
       " 'lay',\n",
       " 'better',\n",
       " 'qualiti',\n",
       " 'egg',\n",
       " 'translat',\n",
       " 'incom',\n",
       " 'loan',\n",
       " 'florenc',\n",
       " 'also',\n",
       " 'benefit',\n",
       " 'fertil',\n",
       " 'poultri',\n",
       " 'drop',\n",
       " 'lot',\n",
       " 'nitrogen',\n",
       " 'addit',\n",
       " 'incom',\n",
       " 'abl',\n",
       " 'support',\n",
       " 'famili',\n",
       " 'improv',\n",
       " 'live',\n",
       " 'condit',\n",
       " 'judith',\n",
       " 'appreci',\n",
       " 'previou',\n",
       " 'kiva',\n",
       " 'loan',\n",
       " 'got',\n",
       " 'enabl',\n",
       " 'stock',\n",
       " 'veget',\n",
       " 'stall',\n",
       " 'addit',\n",
       " 'motorcycl',\n",
       " 'busi',\n",
       " 'well',\n",
       " 'encount',\n",
       " 'breakdownsh',\n",
       " 'request',\n",
       " 'loan',\n",
       " 'ksh10000',\n",
       " 'purchas',\n",
       " 'spare',\n",
       " 'part',\n",
       " 'motor',\n",
       " 'bike',\n",
       " 'need',\n",
       " 'fix',\n",
       " 'thank',\n",
       " 'yehu',\n",
       " 'kiva',\n",
       " 'loan',\n",
       " 'servic',\n",
       " 'improv',\n",
       " 'live',\n",
       " 'standard',\n",
       " 'veronica',\n",
       " 'marri',\n",
       " 'woman',\n",
       " 'four',\n",
       " 'children',\n",
       " ';',\n",
       " 'youngest',\n",
       " '5',\n",
       " 'eldest',\n",
       " '16',\n",
       " 'describ',\n",
       " 'honest',\n",
       " 'courag',\n",
       " 'veronica',\n",
       " 'oper',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'sell',\n",
       " 'product',\n",
       " 'home',\n",
       " 'involv',\n",
       " 'busi',\n",
       " '6',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'kangetha',\n",
       " 'market',\n",
       " 'town',\n",
       " 'maua',\n",
       " 'biggest',\n",
       " 'busi',\n",
       " 'challeng',\n",
       " 'increas',\n",
       " 'cost',\n",
       " 'good',\n",
       " 'use',\n",
       " 'request',\n",
       " 'ke',\n",
       " '20000',\n",
       " 'loan',\n",
       " 'increas',\n",
       " 'stock',\n",
       " 'home',\n",
       " 'product',\n",
       " 'busi',\n",
       " 'goal',\n",
       " 'run',\n",
       " 'anoth',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'within',\n",
       " '5',\n",
       " 'year',\n",
       " 'alic',\n",
       " 'jumamosi',\n",
       " 'lokidiya',\n",
       " 'hardwork',\n",
       " 'ladi',\n",
       " '37',\n",
       " 'year',\n",
       " 'marri',\n",
       " 'togeth',\n",
       " 'four',\n",
       " 'children',\n",
       " 'age',\n",
       " 'nine',\n",
       " 'seven',\n",
       " 'five',\n",
       " 'two',\n",
       " 'year',\n",
       " 'oper',\n",
       " 'boutiqu',\n",
       " 'shop',\n",
       " 'past',\n",
       " 'nine',\n",
       " 'year',\n",
       " 'earn',\n",
       " 'monthli',\n",
       " 'incom',\n",
       " '10000',\n",
       " 'kenyan',\n",
       " 'shill',\n",
       " '(',\n",
       " 'ksh',\n",
       " ')',\n",
       " 'learnt',\n",
       " 'kadet',\n",
       " 'ltd',\n",
       " 'histori',\n",
       " 'mfi',\n",
       " '(',\n",
       " 'microfin',\n",
       " 'institut',\n",
       " ')',\n",
       " 'appli',\n",
       " 'second',\n",
       " 'loan',\n",
       " 'ksh',\n",
       " '40000',\n",
       " 'intend',\n",
       " 'use',\n",
       " 'purchas',\n",
       " 'cloth',\n",
       " 'boutiqu',\n",
       " 'plan',\n",
       " 'use',\n",
       " 'profit',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'start',\n",
       " 'secondari',\n",
       " 'busi',\n",
       " ';',\n",
       " 'dairi',\n",
       " 'farmingalic',\n",
       " 'hope',\n",
       " 'grow',\n",
       " 'busi',\n",
       " 'becom',\n",
       " 'lead',\n",
       " 'local',\n",
       " 'investor',\n",
       " 'kapenguria',\n",
       " 'kenya',\n",
       " 'see',\n",
       " 'children',\n",
       " 'realiz',\n",
       " 'dream',\n",
       " 'life',\n",
       " 'educ',\n",
       " 'jane',\n",
       " 'made',\n",
       " 'live',\n",
       " 'sell',\n",
       " 'cloth',\n",
       " 'town',\n",
       " 'olkal',\n",
       " 'sinc',\n",
       " '2001',\n",
       " '38',\n",
       " 'year',\n",
       " 'old',\n",
       " 'marri',\n",
       " 'paul',\n",
       " 'huri',\n",
       " 'maina',\n",
       " 'four',\n",
       " 'children',\n",
       " 'introduc',\n",
       " 'kadet',\n",
       " 'friend',\n",
       " 'appli',\n",
       " 'first',\n",
       " 'loan',\n",
       " 'plan',\n",
       " 'use',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'cloth',\n",
       " 'sell',\n",
       " 'custom',\n",
       " 'eager',\n",
       " 'buy',\n",
       " 'cloth',\n",
       " 'decemb',\n",
       " 'holiday',\n",
       " 'season',\n",
       " 'sale',\n",
       " 'normal',\n",
       " 'peak',\n",
       " 'franci',\n",
       " 'marri',\n",
       " 'man',\n",
       " '2',\n",
       " 'children',\n",
       " 'describ',\n",
       " 'intellig',\n",
       " 'oper',\n",
       " 'retail',\n",
       " 'busi',\n",
       " 'sell',\n",
       " 'sugar',\n",
       " 'soda',\n",
       " 'flour',\n",
       " 'rice',\n",
       " 'item',\n",
       " 'involv',\n",
       " 'busi',\n",
       " '3',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'strateg',\n",
       " 'place',\n",
       " 'primari',\n",
       " 'custom',\n",
       " 'local',\n",
       " 'use',\n",
       " 'ke',\n",
       " '20000',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'stock',\n",
       " 'sugar',\n",
       " 'bread',\n",
       " 'soap',\n",
       " 'flour',\n",
       " 'item',\n",
       " 'hello',\n",
       " 'lender',\n",
       " '!',\n",
       " 'victoria',\n",
       " 'farm',\n",
       " 'last',\n",
       " 'seven',\n",
       " 'year',\n",
       " 'immens',\n",
       " 'knowledg',\n",
       " 'farm',\n",
       " 'command',\n",
       " 'lot',\n",
       " 'respect',\n",
       " 'among',\n",
       " 'farmer',\n",
       " 'view',\n",
       " 'mentor',\n",
       " 'villag',\n",
       " 'live',\n",
       " 'children',\n",
       " 'kerugoya',\n",
       " 'area',\n",
       " 'kenya',\n",
       " 'known',\n",
       " 'coffe',\n",
       " 'plantat',\n",
       " 'export',\n",
       " 'primari',\n",
       " 'incom',\n",
       " 'sourc',\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data - stem\n",
    "# Porter stemmer is one of several\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in text_corpus_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms: Latent Dirichlet Allocation\n",
    "\n",
    "We've got a clean data set of text! Cleaned, tokenized, and stemmed. Now, let's try turning to our unsupervised model: Latent Dirichlet Allocation, which models topics in a document. \n",
    "\n",
    "The Latent Dirichlet Allocation model looks at text in a \"bag of words\" form, which is the simplest representation of text. Recall that \"bag of words\" means that all the words in a text corpus is counted and put into a dictionary. This is a convenient way to deal with text, but one downside is that no context is retained. In a \"bag of words\" representation, the sentence \"the man ate bread\" is considered the same as \"the bread ate man\". \n",
    "\n",
    "We will use the Python package \"gensim\" because this allows the model to be run on data that might exceed your machine's RAM. This will be important for your own NLP algorithms, as they are typically computationally expensive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kiva_text_clean = [None]*100\n",
    "\n",
    "for i in range(0, len(kiva_text_clean)):\n",
    "    test[i] = [word for word in kiva_text_clean[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clean data \n",
    "\n",
    "# initialize empty list, length = num of descriptions \n",
    "kiva_text_clean = [None]*sample_num\n",
    "for i in range(0, sample_num):\n",
    "    kiva_text_clean[i] = [word for word in kiva_text[i] if word not in stopwords.words('english')]\n",
    "\n",
    "#[porter.stem(t) for t in kiva_text_clean]\n",
    "\n",
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index\n",
    "dictionary = corpora.Dictionary(kiva_text_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in kiva_text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and training LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=2, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.017*\"farming\" + 0.015*\"loan\" + 0.010*\"group\" + 0.010*\"income\" + 0.009*\"children\"'), (1, '0.037*\"business\" + 0.023*\"years\" + 0.021*\"loan\" + 0.015*\"children\" + 0.012*\"married\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=2, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "Farming loans / family business loans? \n",
    "\n",
    "\n",
    "\n",
    "**DEVNOTES** \n",
    "Ideas for research: \n",
    "Try to cluster description based on who the translator is? (need to explain what tf-idf is)\n",
    "Try to parse out all adjectives - see what that looks like per translator ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.cluster in nltk:\n",
      "\n",
      "NAME\n",
      "    nltk.cluster\n",
      "\n",
      "DESCRIPTION\n",
      "    This module contains a number of basic clustering algorithms. Clustering\n",
      "    describes the task of discovering groups of similar items with a large\n",
      "    collection. It is also describe as unsupervised machine learning, as the data\n",
      "    from which it learns is unannotated with class information, as is the case for\n",
      "    supervised learning.  Annotated data is difficult and expensive to obtain in\n",
      "    the quantities required for the majority of supervised learning algorithms.\n",
      "    This problem, the knowledge acquisition bottleneck, is common to most natural\n",
      "    language processing tasks, thus fueling the need for quality unsupervised\n",
      "    approaches.\n",
      "    \n",
      "    This module contains a k-means clusterer, E-M clusterer and a group average\n",
      "    agglomerative clusterer (GAAC). All these clusterers involve finding good\n",
      "    cluster groupings for a set of vectors in multi-dimensional space.\n",
      "    \n",
      "    The K-means clusterer starts with k arbitrary chosen means then allocates each\n",
      "    vector to the cluster with the closest mean. It then recalculates the means of\n",
      "    each cluster as the centroid of the vectors in the cluster. This process\n",
      "    repeats until the cluster memberships stabilise. This is a hill-climbing\n",
      "    algorithm which may converge to a local maximum. Hence the clustering is\n",
      "    often repeated with random initial means and the most commonly occurring\n",
      "    output means are chosen.\n",
      "    \n",
      "    The GAAC clusterer starts with each of the *N* vectors as singleton clusters.\n",
      "    It then iteratively merges pairs of clusters which have the closest centroids.\n",
      "    This continues until there is only one cluster. The order of merges gives rise\n",
      "    to a dendrogram - a tree with the earlier merges lower than later merges. The\n",
      "    membership of a given number of clusters *c*, *1 <= c <= N*, can be found by\n",
      "    cutting the dendrogram at depth *c*.\n",
      "    \n",
      "    The Gaussian EM clusterer models the vectors as being produced by a mixture\n",
      "    of k Gaussian sources. The parameters of these sources (prior probability,\n",
      "    mean and covariance matrix) are then found to maximise the likelihood of the\n",
      "    given data. This is done with the expectation maximisation algorithm. It\n",
      "    starts with k arbitrarily chosen means, priors and covariance matrices. It\n",
      "    then calculates the membership probabilities for each vector in each of the\n",
      "    clusters - this is the 'E' step. The cluster parameters are then updated in\n",
      "    the 'M' step using the maximum likelihood estimate from the cluster membership\n",
      "    probabilities. This process continues until the likelihood of the data does\n",
      "    not significantly increase.\n",
      "    \n",
      "    They all extend the ClusterI interface which defines common operations\n",
      "    available with each clusterer. These operations include.\n",
      "       - cluster: clusters a sequence of vectors\n",
      "       - classify: assign a vector to a cluster\n",
      "       - classification_probdist: give the probability distribution over cluster memberships\n",
      "    \n",
      "    The current existing classifiers also extend cluster.VectorSpace, an\n",
      "    abstract class which allows for singular value decomposition (SVD) and vector\n",
      "    normalisation. SVD is used to reduce the dimensionality of the vector space in\n",
      "    such a manner as to preserve as much of the variation as possible, by\n",
      "    reparameterising the axes in order of variability and discarding all bar the\n",
      "    first d dimensions. Normalisation ensures that vectors fall in the unit\n",
      "    hypersphere.\n",
      "    \n",
      "    Usage example (see also demo())::\n",
      "        from nltk import cluster\n",
      "        from nltk.cluster import euclidean_distance\n",
      "        from numpy import array\n",
      "    \n",
      "        vectors = [array(f) for f in [[3, 3], [1, 2], [4, 2], [4, 0]]]\n",
      "    \n",
      "        # initialise the clusterer (will also assign the vectors to clusters)\n",
      "        clusterer = cluster.KMeansClusterer(2, euclidean_distance)\n",
      "        clusterer.cluster(vectors, True)\n",
      "    \n",
      "        # classify a new vector\n",
      "        print(clusterer.classify(array([3, 3])))\n",
      "    \n",
      "    Note that the vectors must use numpy array-like\n",
      "    objects. nltk_contrib.unimelb.tacohn.SparseArrays may be used for\n",
      "    efficiency when required.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    em\n",
      "    gaac\n",
      "    kmeans\n",
      "    util\n",
      "\n",
      "FILE\n",
      "    c:\\users\\h\\anaconda3\\lib\\site-packages\\nltk\\cluster\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Other clustering algos using nltk\n",
    "\n",
    "help(nltk.cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
